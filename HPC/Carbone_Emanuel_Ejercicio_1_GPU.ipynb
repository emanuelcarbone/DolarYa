{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EA3-Ejercicio 1-GPU.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqmYrGTOCk4i"
      },
      "source": [
        "# 1. Introducción\n",
        "\n",
        "En el siguiente ejercicio se realizará el **producto escalar** entre dos vectores de igual dimensiones.\n",
        "\n",
        "El algoritmo está basado en la función **dot** nivel 1 [1], de la biblioteca **BLAS** [2] que resuelve la ecuación:\n",
        "<center>$res = \\sum_{i-1}^{n} X_i * Y_i$</center>\n",
        "\n",
        "La idea principal es mostrar la perfomance del funcionamiento de **estructuras de una dimensión** para gran cantidad de elementos.\n",
        "\n",
        "Se utilizará Python [3] con las prestaciones brindadas por CUDA [4] para el uso de tecnología GPGPU en la plataforma Colab [5][6].\n",
        "\n",
        "En este último aspecto, se implementó **una función kernel** que se encarga de la **multiplicación** de los componentes de los vectores con el objetivo de paralelizar esta tarea, para luego simplemente sumar los resultados parciales convencionalmente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2vqVVW1G1JW"
      },
      "source": [
        "---\n",
        "# 2. Armado del ambiente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4zdFJlZG1JW"
      },
      "source": [
        "### Importación de módulo **CUDA** y **bibliotecas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tsh_pFJ4G1JW"
      },
      "source": [
        "# Instalamos CUDA para Python\n",
        "!pip install pycuda\n",
        "\n",
        "# Importamos el driver y el compilador para CUDA\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "# Importamos bibliotecas estándares de Python\n",
        "from datetime import datetime\n",
        "import numpy\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzQaWRTtc1Zj"
      },
      "source": [
        "---\n",
        "# 3. Desarrollo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c7mZSnu0M3m"
      },
      "source": [
        "#@title ### 3.1. Parámetros de ejecución {vertical-output: true}\n",
        "#@markdown ---\n",
        "#@markdown Cantidad de elementos de los arrays X e Y:\n",
        "cant_elementos =   50000#@param {type: \"integer\"}\n",
        "#@markdown ---\n",
        "\n",
        "# Validamos la cantidad de elementos de los arrays\n",
        "if not (type(cant_elementos) is int):\n",
        "  raise TypeError(\"El parámetro de entrada debe ser un entero.\") \n",
        "if cant_elementos <= 0:\n",
        "  raise Exception(\"La cantidad de dimensiones de los arrays deben ser al menos 1.\")\n",
        "\n",
        "# Definición de función que transforma el tiempo en milisegundos \n",
        "tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "\n",
        "# El ejercicio podría fallar si no se importaron los recursos necesarios\n",
        "# Es por eso que envolvemos el código en un bloque try, de esta forma\n",
        "# se le indica al usuario cómo proceder\n",
        "try: \n",
        "  # Capturamos el tiempo inicial\n",
        "  tiempo_total = datetime.now()\n",
        "\n",
        "  # CPU - Defino los vectores y el resultado en CPU\n",
        "  x_cpu = numpy.random.randint(1, 10, cant_elementos)\n",
        "  x_cpu = x_cpu.astype(numpy.int64())\n",
        "  y_cpu = numpy.random.randint(1, 10, cant_elementos)\n",
        "  y_cpu = y_cpu.astype(numpy.int64())\n",
        "\n",
        "  # GPU - Reservo la memoria GPU en base a los vectores creados\n",
        "  x_gpu = cuda.mem_alloc(x_cpu.nbytes)\n",
        "  y_gpu = cuda.mem_alloc(y_cpu.nbytes)\n",
        "\n",
        "  # GPU - Copio la memoria desde CPU a GPU\n",
        "  cuda.memcpy_htod(x_gpu, x_cpu)\n",
        "  cuda.memcpy_htod(y_gpu, y_cpu)\n",
        "\n",
        "  # CPU - Defino la función kernel que multiplica los elementos\n",
        "  module_mul = SourceModule(\"\"\"\n",
        "    __global__ void kernel_dot_mul(int n, int *X, int *Y) {\n",
        "        \n",
        "      int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "      if(idx < n) {\n",
        "        Y[idx] = X[idx] * Y[idx];\n",
        "      }\n",
        "\n",
        "    }\n",
        "  \"\"\")\n",
        "\n",
        "  # CPU - Obtenemos la función kernel creada\n",
        "  kernel_mul = module_mul.get_function(\"kernel_dot_mul\")\n",
        "\n",
        "  # Capturamos el tiempo inicial del algoritmo y de GPU\n",
        "  tiempo_algoritmo = datetime.now()\n",
        "  tiempo_gpu = datetime.now()\n",
        "\n",
        "  # GPU - Definimos la dimensión de threads y bloques\n",
        "  dim_hilo = 16\n",
        "  dim_bloque = numpy.int((cant_elementos + dim_hilo - 1) / dim_hilo)\n",
        "\n",
        "  # GPU - Ejecuta el kernel para la multiplicación\n",
        "  kernel_mul(numpy.int64(cant_elementos),\n",
        "            x_gpu, y_gpu, \n",
        "            block=(dim_hilo, 1, 1), grid=(dim_bloque, 1, 1))\n",
        "\n",
        "  # GPU - Copiamos el resultado desde la memoria GPU a CPU\n",
        "  cuda.memcpy_dtoh(y_cpu, y_gpu)\n",
        "\n",
        "  # Capturamos el tiempo total de GPU\n",
        "  tiempo_gpu = datetime.now() - tiempo_gpu\n",
        "  \n",
        "  # Computamos los resultados parciales\n",
        "  res_cpu = 0\n",
        "  for e in range(0, cant_elementos):\n",
        "    res_cpu += y_cpu[e]\n",
        "\n",
        "  # Capturamos el tiempo total del algoritmo y de todo el ejercicio\n",
        "  tiempo_algoritmo = datetime.now() - tiempo_algoritmo\n",
        "  tiempo_total = datetime.now() - tiempo_total\n",
        "\n",
        "  # Mostramos el resultado del proceso\n",
        "  print(\"Cantidad de elementos en los arrays: \", cant_elementos)\n",
        "  print(\"Dim. Thread x: \", dim_hilo, \" - Dim. Bloque x:\", dim_bloque, \"\\n\")\n",
        "  print(\"Tiempo GPU: \", tiempo_en_ms(tiempo_gpu), \"[ms]\")\n",
        "  print(\"Tiempo DOT: \", tiempo_en_ms(tiempo_algoritmo), \"[ms]\")\n",
        "  print(\"Tiempo total: \", tiempo_en_ms(tiempo_total), \"[ms]\\n\")\n",
        "  print(\"Resultado de DOT: \", res_cpu)\n",
        "except:\n",
        "  print(\"Ups! Algo salió mal, ¿Realizó la preparación previa del ambiente?\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EALIlyyG6iqP"
      },
      "source": [
        "---\n",
        "# 4. Tabla de pasos de ejecución del programa\n",
        "\n",
        "\n",
        "Procesador|Función|Detalle\n",
        "---|---|---\n",
        "CPU|pip install pycuda|Instala el módulo de CUDA para Python.\n",
        "CPU|import|Importa los módulos para funcionar.\n",
        "CPU|@param|Lectura del tamaño de vectores desde Colab.\n",
        "CPU|datetime.now()|Toma el tiempo inicial del ejercicio.\n",
        "CPU|numpy.random.randint|Inicializa los vectores X e Y con enteros aleatorios.\n",
        "CPU|astype|Castea los vectores a un tipo de dato especificado.\n",
        "CPU|numpy.empty_like|Retorna un array con la misma forma y tipo que el especificado.\n",
        "**GPU**|cuda.mem_alloc()|Reserva la memoria en GPU.\n",
        "**GPU**|cuda.memcpy_htod()|Copia la memoria desde el CPU al GPU.\n",
        "CPU|SourceModule()|Define el código de las funciones kernel. \n",
        "CPU|module.get_function()|Obtenemos las funciones del kernel GPU.\n",
        "CPU|datetime.now()|Toma el tiempo inicial del algoritmo y de GPU.\n",
        "CPU|dim_tx/dim_bx|Calcula las dimensiones.\n",
        "**GPU**|kernel_mul y kernel_sum|Ejecuta el kernel en GPU\n",
        "**GPU**|cuda.memcpy_dtoh()|Copia el resultado desde memoria GPU a memoria CPU.\n",
        "CPU|datetime.now()|Toma el tiempo total de GPU.\n",
        "CPU|for(...)|Computa los resultados parciales de DOT\n",
        "CPU|datetime.now()|Toma el tiempo total del algoritmo y del ejercicio.\n",
        "CPU|print()|Informa los resultados.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzgZkrQD-UTy"
      },
      "source": [
        "---\n",
        "# 5. Conclusiones\n",
        "\n",
        "Se realizaron las siguientes pruebas:\n",
        "\n",
        "Cantidad de elementos|Tiempo DOT [ms]|Tiempo Total [ms]|Relación tiempos [%] \n",
        "---|---|---|---\n",
        "50K|12.71|16.12|78.46\n",
        "500k|129.26|156.58|82.55\n",
        "5M|1300.77|1524.78|85.30\n",
        "50M|12443.11|14697.39|84.66\n",
        "\n",
        "Podemos decir que:\n",
        "*   A comparación de la versión CPU, el tiempo necesario que lleva el algoritmo bajó aproximadamente un 10% respecto al total, esto claramente se debe al **paralelismo** durante la realización de los cálculos intermedios. Antes, en CPU, absolutamente todos los cálculos se debían hacer uno atrás de otro, por lo que terminaba siendo razonable que casi todo el tiempo de ejecución se lo llevase el algortimo. Ahora, en GPU, los cálculos parciales de los componentes pueden ser paralelizados, simplificando así la tarea, y por ende, haciendo más rápido el algoritmo.\n",
        "\n",
        "*   Si bien el tiempo total parece que **continua creciendo linealmente**, este se **redujo mucho** respecto a la versión CPU, con un aproximado del 70%. La linealidad continúa siendo razonable, ya que cuantos más elementos tengan los vectores, más se tardarán en crear y más tardarán en ser trasladados desde la memoria CPU a memoria GPU y viceversa. Sin embargo, como el tiempo total se ve ampliamente reducido con respecto a la versión CPU, podemos considerar que el problema adquiere la complejidad de una recta con menor pendiente.\n",
        "\n",
        "Consideramos, entonces, que el uso de GPU en operaciones entre estructuras de una dimensión viene muy bien para esta clase de problemas ya que muchas veces todo se reduce a pequeños problemas independientes que pueden ser tomados por los distintos hilos. Como detalle adicional, comentamos que realizar la suma final a través de hilos no mejoraba significativamente el algoritmo, ya que había mucho overhead de por medio durante la sincronización de los mismos debido a que accedían al mismo espacio de memoria, cosa que no ocurría con la multiplicación de los componentes de los vectores. \n",
        "\n",
        "Una manera de mejorar el ejercicio podría ser el hecho de poder elegir distintas operaciones entre vectores conocidas en el álgebra lineal para poder comparar cuáles son más costosas (suma de vectores, cálculo de producto vectorial, etc.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hn6HOCYEjyY"
      },
      "source": [
        "---\n",
        "# 6. Bibliografia\n",
        "\n",
        "[1] Función DOT de biblioteca BLAS: [Página Web](https://software.intel.com/content/www/us/en/develop/documentation/mkl-developer-reference-c/top/blas-and-sparse-blas-routines/blas-routines/blas-level-1-routines-and-functions/cblas-dot.html)\n",
        "\n",
        "[2] Biblioteca BLAS: [BLAS](http://www.netlib.org/blas/)\n",
        "\n",
        "[3] Introducción a Python: [Página Colab](https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/Python_Basico.ipynb)\n",
        "\n",
        "[4] Documentación de CUDA para Python: [Página web](https://documen.tician.de/pycuda/index.html)\n",
        "\n",
        "[5] Sintaxis Markdown Colab: [PDF](https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/markdown-cheatsheet-online.pdf)\n",
        "\n",
        "[6] Tutorial Point Colab: [PDF](https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/markdown-cheatsheet-online.pdf)\n",
        "\n"
      ]
    }
  ]
}