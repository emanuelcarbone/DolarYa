{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EA3-Ejercicio 1-GPU.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"WqmYrGTOCk4i"},"source":["# 1. Introducción\n","\n","En el siguiente ejercicio se realizará el **producto escalar** entre dos vectores de igual dimensiones.\n","\n","El algoritmo está basado en la función **dot** nivel 1 [1], de la biblioteca **BLAS** [2] que resuelve la ecuación:\n","<center>$res = \\sum_{i-1}^{n} X_i * Y_i$</center>\n","\n","La idea principal es mostrar la perfomance del funcionamiento de **estructuras de una dimensión** para gran cantidad de elementos.\n","\n","Se utilizará Python con las prestaciones brindadas por CUDA para el uso de tecnología GPGPU.\n","\n","En este último aspecto, se implementaron **dos funciones kernel** que se encargan de la **multiplicación** de los componentes de los vectores y la **suma** de esos resultados parciales, respectivamente."]},{"cell_type":"markdown","metadata":{"id":"i2vqVVW1G1JW"},"source":["---\n","# 2. Armado del ambiente"]},{"cell_type":"markdown","metadata":{"id":"dnJGvX4aG1JW"},"source":["### Instalando el **módulo CUDA** de Python"]},{"cell_type":"code","metadata":{"id":"ccGiUO6TG1JW"},"source":["!pip install pycuda"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j4zdFJlZG1JW"},"source":["### Importación de **bibliotecas**"]},{"cell_type":"code","metadata":{"id":"Tsh_pFJ4G1JW"},"source":["# Importamos el driver y el compilador para CUDA\n","import pycuda.driver as cuda\n","import pycuda.autoinit\n","from pycuda.compiler import SourceModule\n","\n","# Importamos bibliotecas estándares de Python\n","from datetime import datetime\n","import numpy\n","import math"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NzQaWRTtc1Zj"},"source":["---\n","# 3. Desarrollo"]},{"cell_type":"code","metadata":{"id":"9c7mZSnu0M3m"},"source":["#@title ### 3.1. Parámetros de ejecución {vertical-output: true}\n","#@markdown ---\n","#@markdown Cantidad de elementos de los arrays X e Y:\n","cant_elementos =   5000000#@param {type: \"number\"}\n","#@markdown ---\n","\n","\n","# Definición de función que transforma el tiempo en milisegundos \n","tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n","\n","# Capturamos el tiempo inicial\n","tiempo_total = datetime.now()\n","\n","# CPU - Defino los vectores y el resultado en CPU\n","x_cpu = numpy.random.randint(1, 10, cant_elementos)\n","x_cpu = x_cpu.astype(numpy.int64())\n","y_cpu = numpy.random.randint(1,10, cant_elementos)\n","y_cpu = y_cpu.astype(numpy.int64())\n","res_cpu = numpy.empty_like(numpy.int64())\n","\n","# CPU - Reservo la memoria GPU en base a los vectores creados\n","x_gpu = cuda.mem_alloc(x_cpu.nbytes)\n","y_gpu = cuda.mem_alloc(y_cpu.nbytes)\n","res_gpu = cuda.mem_alloc(res_cpu.nbytes)\n","\n","# GPU - Copio la memoria desde CPU a GPU\n","cuda.memcpy_htod(x_gpu, x_cpu)\n","cuda.memcpy_htod(y_gpu, y_cpu)\n","cuda.memcpy_htod(res_gpu, res_cpu)\n","\n","# CPU - Defino la función kernel que multiplica los elementos\n","module_mul = SourceModule(\"\"\"\n","__global__ void kernel_dot_mul(int n, int *X, int *Y) {\n","  \n","  int idx = threadIdx.x + blockIdx.x * blockDim.x;\n","  if(idx < n) {\n","    Y[idx]  = X[idx] * Y[idx];\n","  }\n","\n","}\n","\"\"\")\n","\n","# CPU - Defino la función kernel que suma los elementos\n","module_sum = SourceModule(\"\"\"\n","__global__ void kernel_dot_sum(int n, int *Y) {\n","  \n","  int idx = threadIdx.x + blockIdx.x * blockDim.x;\n","  if(2*idx + 1 < n) {\n","    Y[idx] = Y[2*idx] + Y[2*idx + 1];\n","  }\n","  else if(2*idx + 1 == n) {\n","    Y[0] += Y[2*idx];\n","  }\n","\n","}\n","\"\"\")\n","\n","# CPU - Obtenemos la funciones kernel creadas\n","kernel_mul = module_mul.get_function(\"kernel_dot_mul\")\n","kernel_sum = module_sum.get_function(\"kernel_dot_sum\")\n","\n","# Capturamos el tiempo inicial de GPU\n","tiempo_gpu = datetime.now()\n","\n","# GPU - Definimos la dimensión de threads y bloques\n","dim_hilo = 256\n","dim_bloque = numpy.int((cant_elementos + dim_hilo - 1) / dim_hilo)\n","\n","# GPU - Ejecuta el kernel para la multiplicación\n","kernel_mul(numpy.int64(cant_elementos), \n","           x_gpu, y_gpu, \n","           block=(dim_hilo, 1, 1), grid=(dim_bloque, 1, 1))\n","\n","# GPU - Ejecuta el kernel para las sumas\n","n = cant_elementos\n","while n/2 >= 1:\n","  kernel_sum(numpy.int64(n), \n","             y_gpu, \n","             block=(dim_hilo, 1, 1), grid=(dim_bloque, 1, 1))\n","  n = math.floor(n/2)\n","\n","# Capturamos el tiempo total que tardó GPU\n","tiempo_gpu = datetime.now() - tiempo_gpu\n","\n","# GPU - Copiamos el resultado desde la memoria GPU a CPU\n","cuda.memcpy_dtoh(res_cpu, y_gpu)\n","\n","# Capturamos el tiempo total de todo el ejercicio\n","tiempo_total = datetime.now() - tiempo_total\n","\n","# Mostramos el resultado del proceso\n","print(\"Cantidad de elementos en los arrays: \", cant_elementos)\n","print(\"Dim. Thread x: \", dim_hilo, \" - Dim. Bloque x:\", dim_bloque, \"\\n\")\n","print(\"Tiempo total: \", tiempo_en_ms(tiempo_total), \"[ms]\")\n","print(\"Tiempo GPU: \", tiempo_en_ms(tiempo_gpu), \"[ms]\\n\")\n","print(\"Resultado de DOT: \", res_cpu)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EALIlyyG6iqP"},"source":["---\n","# 4. Tabla de pasos de ejecución del programa\n","\n","\n"," Procesador | Funciòn | Detalle\n","------------|---------|----------\n","CPU      |  pip install pycuda    | Instala el módulo de CUDA para Python.\n","CPU      |  import                | Importa los módulos para funcionar.\n","CPU      |  @param                | Lectura del tamaño de vectores desde Colab.\n","CPU      |  datetime.now()        | Toma el tiempo inicial del ejercicio.\n","CPU      |  numpy.random.randint  | Inicializa los vectores X e Y con enteros aleatorios.\n","CPU      | astype                 | Castea los vectores a un tipo de dato especificado.\n","CPU      | numpy.empty_like       | Retorna un array con la misma forma y tipo que el especificado.\n","**GPU**  |  cuda.mem_alloc()      | Reserva la memoria en GPU.\n","**GPU**  |  cuda.memcpy_htod()    | Copia la memoria desde el CPU al GPU.\n","CPU      |  SourceModule()        | Define el código de las funciones kernel. \n","CPU      |  module.get_function() | Obtenemos las funciones del kernel GPU.\n","CPU      |  datetime.now()        | Toma el tiempo inicial de GPU.\n","CPU      |  dim_tx/dim_bx         | Calcula las dimensiones.\n","**GPU**  |  kernel_mul y kernel_sum              | Ejecuta el kernel en GPU\n","CPU      |  datetime.now()        | Toma el tiempo total de GPU.\n","**GPU**      |  cuda.memcpy_dtoh( )   | Copia el resultado desde memoria GPU a memoria CPU.\n","CPU      |  datetime.now()        | Toma el tiempo total del ejercicio.\n","CPU      |  print()               | Informa los resultados.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"TzgZkrQD-UTy"},"source":["---\n","# 5. Conclusiones\n","\n"]},{"cell_type":"markdown","metadata":{"id":"6hn6HOCYEjyY"},"source":["---\n","# 6. Bibliografia\n","\n","[1] Función DOT de biblioteca BLAS: [Página Web](https://software.intel.com/content/www/us/en/develop/documentation/mkl-developer-reference-c/top/blas-and-sparse-blas-routines/blas-routines/blas-level-1-routines-and-functions/cblas-dot.html)\n","\n","[2] Biblioteca BLAS: [BLAS](http://www.netlib.org/blas/)\n","\n","\n"]}]}